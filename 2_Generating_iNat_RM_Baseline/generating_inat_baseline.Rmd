---
title: "Generating baseline from iNat data to compare users"
author: "Biohack team 12"
date: "09/11/2021"
output: html_document
---


```{r}
#devtools::install_github('biologicalrecordscentre/recorderMetrics')

library(rinat)

library(adehabitatHR)
library(raster)
library(sp)
library(rgdal)
library(recorderMetrics)

library(dplyr)
library(purrr)

library(httr)
library(jsonlite)

library(sf)

library(ggplot2)

library(stringr)

library(geosphere)


library(sp)
library(rworldmap)

source("2_Generating_iNat_RM_Baseline/coords2country.R")
source("2_Generating_iNat_RM_Baseline/get_inat_obs_user_tweaked.R")

library(sqldf)
library(readr)
```

## Get data

### Getting a sample of users

Provide information about how we download the data

Turn users into usernames

```{r}
#load users
recorded_by <- readLines("Getting_Random_Observers/data/spain_100obs_observers_2021-11-09_12-03.txt")

usernames <- c()

for (i in 1:length(recorded_by)){
  res = GET("https://api.inaturalist.org/v1/users/autocomplete",
    query = list(q = recorded_by[i]))
  
  data = fromJSON(rawToChar(res$content))
  
  if (nrow(data$results)>1) {
    print("multiple matches :S")
  } else if (nrow(data$results)==1) {
    print("one match good! :D")
    username <- data$results$login
    usernames <- append(usernames,username)
  } else {
    "no matches :("
  }
  Sys.sleep(1)
}

saveRDS(usernames,"2_Generating_iNat_RM_Baseline/data/usernames.rds")

```



### Get observations for users

Option 1: use inaturlist API

```{r}
if(F){
  #load usernames from whatever source
  usernames <- readRDS("2_Generating_iNat_RM_Baseline/data/usernames.rds")
  
  for (i in 1:length(usernames)){
    # using function adapted from rinat package
    print(i)
    tryCatch({
      user_observations <- get_inat_obs_user_tweaked(usernames[i],maxresults = 5000,queryextra = "&taxon_id=47126&place_id=6774")
      saveRDS(user_observations,paste0("2_Generating_iNat_RM_Baseline/data/user_obvs/observations_",usernames[i],".rds"))
      },
      error = function(cond){
        print(cond)
      })
    
    Sys.sleep(1)
  }
}

```

Option 2: use iNat dump

Using: https://stackoverflow.com/questions/15967226/skip-some-rows-in-read-csv-in-r/15967406#15967406

```{r}
#load usernames from whatever source
usernames <- readRDS("2_Generating_iNat_RM_Baseline/data/usernames.rds")

#country_code <- "ES" # ISO alpha 2

observations <- read_delim("data_inat/observations.csv", 
    delim = "\t", escape_double = FALSE, 
    col_types = cols(observed_on = col_date(format = "%Y-%m-%d")), 
    trim_ws = TRUE)


for (cc in "ES"){
  country_code <- cc %>% as.character()
  print(country_code)
  country_poly <- countriesCoarse[countriesCoarse$ISO_A2 == country_code,]
  country_extent <- bbox(country_poly)
  
  #do a crop of the extent of the country to lose some data 
  country_observations <- observations %>% filter(
    longitude > country_extent["x","min"],
    longitude < country_extent["x","max"],
    latitude > country_extent["y","min"],
    latitude < country_extent["y","max"]
  )
  
  xy <- country_observations %>% select(longitude,latitude)
  
  # lets exclude non-spain records that have slipped through the gap
  spdf <- SpatialPointsDataFrame(coords = xy, data = country_observations,
                                 proj4string = CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"))
  country_observations$country_check <- coords2country(spdf) %>% as.character()
  
  country_observations <- country_observations %>% filter(country_check == country_code)
  
  #observer record tally
  user_ids <- country_observations %>% 
    group_by(observer_id) %>%
    summarise(nrecords = n()) %>%
    filter(nrecords>99) %>% 
    pull(observer_id)
  
  #if over 1000 records then radnomly sample 1000
  if(length(user_ids)>1000){
    sample(user_ids,1000,replace = F)
  }
  
  #select users that have submitted 100 or more records
  country_observations_select <- country_observations %>% filter(observer_id %in% user_ids)
  
  #save
  saveRDS(country_observations_select,paste0("2_Generating_iNat_RM_Baseline/data/observations/by_country/observations_",country_code,".rds"))
}

#remove the big dataframe from memory to save space
rm(observations)

```




Preparing data ready for recorderMetrics

Load data from approach 1 (using iNat API)

```{r}
if(F){
  #Combine into one dataframe
  all_observations_raw <- paste0("2_Generating_iNat_RM_Baseline/data/user_obvs/",list.files(path = "2_Generating_iNat_RM_Baseline/data/user_obvs", pattern = ".rds")) %>%
    map(readRDS) %>% 
    bind_rows()
  #see what columns we have to play with
  #all_observations_raw %>% str()
  
  #get columns and rename
  all_observations <- all_observations_raw %>% 
    select(id = id,
           recorder = user_login,
           species = scientific_name,
           date = observed_on,
           long = longitude,
           lat = latitude,
           quality_grade = quality_grade) %>%
    mutate(species_level = F,date = as.Date(date)) %>%
    filter(!is.na(long),!is.na(lat),!is.na(date)) #remove observations without locaton or date
}

all_observations$species_level[str_detect(all_observations$species, " ")] <- T

```

Load data from approach 2 (using iNat bulk data)

```{r}
country_code <- "ES"

all_observations_raw <- readRDS(paste0("2_Generating_iNat_RM_Baseline/data/observations/by_country/observations_",country_code,".rds"))

all_observations <- all_observations_raw %>% 
    select(id = observation_uuid,
           recorder = observer_id,
           species = taxon_id,
           date = observed_on,
           long = longitude,
           lat = latitude,
           quality_grade = quality_grade) %>%
    filter(!is.na(long),!is.na(lat),!is.na(date)) #remove observations without location or date

```


Get square km


```{r}

#get proj string from country code (temporary)
get_proj_from_ISO <- function(ISO_A2 = "ES"){
  "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"
}


proj_string <- get_proj_from_ISO(country_code)

#quick look at the data
#all_observations %>% str()

#generating sites
#option 1: 1km grid squares using spanish national grid

# generate: km_sq by projecting to spanish national grid


if(F){
  # firstly lets exclude non-spain records that have slipped through the gap
  xy <- all_observations %>% select(long,lat)
  spdf <- SpatialPointsDataFrame(coords = xy, data = all_observations,
                                 proj4string = CRS(proj_string))
  
  all_observations$country <- coords2country(spdf) %>% as.character() # add coutnry clumn to dataframe
  all_observations <- all_observations %>% filter(country == "Spain",long>-10) # exclude non-spain records (and canary island records by filtering by longitude)
  
  #plot it to make sure it's all in spain
  plot(all_observations$long, all_observations$lat)
}

#make into spatial data frame, convert to sf, transform to spanish grid, get coordinates and round to nearest 1000
xy <- all_observations %>% select(long,lat)
spdf <- SpatialPointsDataFrame(coords = xy, data = all_observations,
                               proj4string = CRS(proj_string))
spdf_grids <- spdf %>% 
  st_as_sf() %>% 
  st_transform(spdf,crs = 2062) %>% 
  st_coordinates() %>% 
  round(-3) # rounds to nearest 1000m, not rounding down

#add the column to the data frame
all_observations$km_sq <- paste0(spdf_grids[,1],",",spdf_grids[,2])

saveRDS(all_observations,paste0("2_Generating_iNat_RM_Baseline/data/observations/by_country/observations_",country_code,"_processed.rds"))
```

An alternative approach for creating 'sites' by clustering - doesn't work yet

```{r}
if(F){
  # option 2: clustering
  spdf <- SpatialPointsDataFrame(coords = xy, data = all_observations,
                                 proj4string = CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"))
  mdist <- distm(spdf) # doesn't work because it wants to make a massive vector
  
  hc <- hclust(as.dist(mdist), method="complete")
  
  # define the distance threshold, in this case 40 m
  d=100
  
  # define clusters based on a tree "height" cutoff "d" and add them to the SpDataFrame
  cutree(hc, h=d)
}
```

Save the outputs

```{r}
write.csv(all_observations,"2_Generating_iNat_RM_Baseline/data/observations/baseline_observations_spain_plants.csv")
saveRDS(all_observations,"2_Generating_iNat_RM_Baseline/data/observations/baseline_observations_spain_plants.rds")
```


## Metric-ify

### Plug into recorder metrics

```{r}

all_observations <- readRDS("2_Generating_iNat_RM_Baseline/data/observations/baseline_observations_spain_plants.rds")

record_count <- all_observations %>% group_by(recorder) %>% summarise(n_records = n())

#not sure if this works
metrics_axes <- predictAxes(data = all_observations,
                            recorders  = unique(all_observations$recorder)[1:100])
# 
str(metrics_axes)

#pairwise plot
ggpairs(data = metrics_axes$axes,columns = 2:ncol(metrics_axes$axes))


#actiity ratio
ar <- activityRatio(recorder_name = unique(all_observations$recorder)[1],
                   data = all_observations,
                   recorder_col = 'recorder',
                   date_col = 'date')

#list length
LL <- listLength(data = all_observations,
                 recorder_name = unique(all_observations$recorder)[1],
                 threshold = 10,
                 plot = T,
                 sp_col = 'species',
                 date_col = 'date',
                 recorder_col = 'recorder',
                 location_col = 'km_sq')


```


### do stuff









